{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eIce92bDiD2H"
      },
      "source": [
        "# FixMatch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions.transforms import LowerCholeskyTransform\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# vizualisation\n",
        "import torchsummary\n",
        "\n",
        "# transforms\n",
        "import torchvision.transforms as T\n",
        "import kornia.augmentation as K\n",
        "from torchvision.transforms.v2 import RandAugment\n",
        "\n",
        "# metrics\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "# torchvision\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from torchview import draw_graph\n",
        "from IPython.display import display\n",
        "from IPython.core.display import SVG, HTML\n",
        "from tqdm import tqdm\n",
        "\n",
        "# typing\n",
        "from typing import Callable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set device\n",
        "if float(torch.__version__.split(\".\")[1]) >= 13 and torch.has_mps:\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_SHAPE = (3, 32, 32)\n",
        "# See Table 4\n",
        "TAU = 0.95\n",
        "LAMBDA_U = 1\n",
        "MU = 7\n",
        "BATCH_SIZE = 64 # B\n",
        "LR = 0.03\n",
        "BETA = 0.9\n",
        "WEIGHT_DECAY = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78cLXTmIjUld"
      },
      "outputs": [],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=T.ToTensor())\n",
        "\n",
        "trainset, validset = torch.utils.data.random_split(trainset, [0.90, 0.10])\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=T.ToTensor())\n",
        "                                        \n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=4)\n",
        "\n",
        "validloader = DataLoader(validset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=4)                                  \n",
        "                                       \n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=True, num_workers=4)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utils function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.Figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_images(images: torch.Tensor, true_labels: torch.Tensor, predicted_labels: torch.Tensor) -> plt.Figure: # type: ignore\n",
        "    assert images.shape[0] >= 16, \"Not enough images to plot\"\n",
        "    assert images.shape[0] == true_labels.shape[0] == predicted_labels.shape[0], \"Number of images and labels do not match\"\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(10,10))\n",
        "    axes = axes.ravel() # type: ignore\n",
        "\n",
        "    for i in range(16):\n",
        "        axes[i].imshow(images[i].cpu().numpy().transpose(1, 2, 0))\n",
        "        axes[i].set_title(f\"True: {classes[true_labels[i]]}\\nPredicted: {classes[predicted_labels[i]]}\")\n",
        "        axes[i].axis('off')\n",
        "        fig.subplots_adjust(hspace=0.5)\n",
        "\n",
        "    return fig\n",
        "\n",
        "def plot_transform(images: torch.Tensor, transform: Callable[[torch.Tensor], torch.Tensor], transform_name: str | None = None) -> plt.Figure:     # type: ignore\n",
        "    assert images.shape[0] >= 4, \"Not enough images to plot\"\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(10,5))\n",
        "    images = images[:4]\n",
        "    images_transformed = transform(images)\n",
        "    transform_name = transform_name if transform_name is not None else ''\n",
        "\n",
        "    for i in range(4):\n",
        "        axes[0][i].imshow(images[i].cpu().numpy().transpose(1, 2, 0))\n",
        "        axes[0][i].set_title(f\"Original\")\n",
        "        axes[0][i].axis('off')\n",
        "\n",
        "        axes[1][i].imshow(images_transformed[i].cpu().numpy().transpose(1, 2, 0))\n",
        "        axes[1][i].set_title(f\"Transformed {transform_name}\")\n",
        "        axes[1][i].axis('off')\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rHIndKj4l42E"
      },
      "source": [
        "## RandAugment\n",
        "\n",
        "Pour implémenter l'augmentation forte dans FixMatch, vous aurez besoin d'une politique d'augmentation de données apprise par renforcement. La méthode RandAugment a été implémentée dans la bibliothèque imgaug, voici comment l'utiliser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# implementation in PyTorch of a simple CNN\n",
        "\n",
        "class ConvNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple CNN for CIFAR10\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_32 = nn.Conv2d(3, 32, kernel_size=3, padding='same')\n",
        "        self.conv_64 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
        "        self.conv_96 = nn.Conv2d(64, 96, kernel_size=3, padding='same')\n",
        "        self.conv_128 = nn.Conv2d(96, 128, kernel_size=3, padding='same')\n",
        "        self.fc_512 = nn.Linear(512, 512)\n",
        "        self.fc_10 = nn.Linear(512, 10)\n",
        "        self.max_pool = nn.MaxPool2d(2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.conv_32(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.conv_64(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.conv_96(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.conv_128(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc_512(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc_10(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_graph = draw_graph(ConvNN(), input_size=[(BATCH_SIZE, *IMG_SHAPE)], graph_name='./figures/model', graph_dir=\"LR\", device='cpu', expand_nested=True, save_graph=True)\n",
        "\n",
        "display(\n",
        "    HTML(\"<h2>Model</h2>\"),\n",
        "    SVG(model_graph.visual_graph._repr_image_svg_xml()),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sched import scheduler\n",
        "\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "model = ConvNN().to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=BETA)\n",
        "scheduler = None\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Training\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for (images, labels) in (pbar := tqdm(trainloader, desc=f\"Epoch {epoch: >5}\")) :\n",
        "        # extract mini batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # forward pass\n",
        "        outputs = model.forward(images)\n",
        "        label_pred = outputs.argmax(dim=1)\n",
        "        loss = criterion.forward(outputs, labels)\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        # update metrics\n",
        "        epoch_loss += loss.item()*images.size(0)/len(trainloader)\n",
        "        # print statistics\n",
        "        pbar.set_postfix(\n",
        "            {\n",
        "                \"train_loss\": f\"{loss.item():.2f}\",\n",
        "                \"epoch_loss\": f\"{epoch_loss:.2f}\",\n",
        "                \"lr\": f\"{optimizer.param_groups[0]['lr']:.3f}\",\n",
        "            }\n",
        "        )\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_epoch_loss = 0.0\n",
        "        for (images_val, label_val) in (pbar := tqdm(validloader, desc=f\"Epoch val {epoch: >1}\")):\n",
        "            images_val, label_val = images_val.to(device), label_val.to(device)\n",
        "            outputs_val = model.forward(images_val)\n",
        "            label_pred_val = outputs_val.argmax(dim=1)\n",
        "            loss_val = criterion.forward(outputs_val, label_val)\n",
        "            val_epoch_loss += loss_val.item()*images_val.size(0)/len(validloader)\n",
        "            pbar.set_postfix(\n",
        "                {\n",
        "                    \"val_loss\": f\"{loss_val.item():.2f}\",\n",
        "                    \"val_epoch_loss\": f\"{val_epoch_loss:.2f}\",\n",
        "                    \"accuracy\": f\"{accuracy(label_val.cpu(), label_pred_val.cpu()):.2f}\",\n",
        "                }\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_image, test_labels = testloader.__iter__().__next__()\n",
        "test_image = test_image.to(device)\n",
        "outputs_test = model(test_image)\n",
        "label_pred_test = outputs_test.argmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig1 = plot_images(test_image, test_labels, label_pred_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FixMatch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "# Model\n",
        "model = ConvNN().to(device)\n",
        "\n",
        "# Criterion\n",
        "supervised_criterion = nn.CrossEntropyLoss().to(device)\n",
        "unsupervised_criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# Metrics\n",
        "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "# Optimizer & Scheduler\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=BETA)\n",
        "optimizer = torch.optim.AdamW(model.parameters())\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transform\n",
        "weak_transform = K.ImageSequential(\n",
        "    K.RandomHorizontalFlip(p=0.50), # 50% chance of flipping\n",
        "    K.RandomAffine(degrees=0, translate=(0.125, 0.125)), # 12.5% chance of vertical of horizontal translation\n",
        ")\n",
        "\n",
        "strong_transform = K.ImageSequential(\n",
        "    K.auto.AutoAugment(\"cifar10\"),\n",
        "    # K.auto.RandAugment(\"cifar10\"),\n",
        "    # K.RandomErasing(p=0.25, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0),\n",
        ")\n",
        "\n",
        "fig2 = plot_transform(test_image, weak_transform, \"Weak\")\n",
        "fig3 = plot_transform(test_image, strong_transform, \"Strong\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split trainset into train and validation\n",
        "trainset_sup, trainset_unsup = torch.utils.data.random_split(trainset, [1/(1+MU), MU/(1+MU)])\n",
        "trainloader_sup = DataLoader(\n",
        "    trainset_sup, batch_size=BATCH_SIZE,\n",
        "    shuffle=True, num_workers=4\n",
        ")\n",
        "trainloader_unsup = DataLoader(\n",
        "    trainset_unsup, batch_size=BATCH_SIZE,\n",
        "    shuffle=True, num_workers=4\n",
        ")\n",
        "\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    # Training\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    trainloader_sup_iter = iter(trainloader_sup)\n",
        "\n",
        "    for batch_idx in (pbar := tqdm(range(len(trainloader_sup)), desc=f\"Epoch {epoch: >5}\")):\n",
        "        # extract mini batch\n",
        "        images_sup, labels_sup = trainloader_sup_iter.__next__()\n",
        "        images_sup, labels_sup = images_sup.to(device), labels_sup.to(device)\n",
        "        \n",
        "        # Supervised part\n",
        "        with torch.no_grad():\n",
        "            images_sup_weak = weak_transform(images_sup)\n",
        "        logits_weak_pred_sup = model.forward(images_sup_weak)\n",
        "        proba_weak_pred_sup = torch.nn.functional.softmax(logits_weak_pred_sup, dim=1)\n",
        "        label_weak_pred_sup = proba_weak_pred_sup.argmax(dim=1)\n",
        "        loss_weak_sup = supervised_criterion.forward(logits_weak_pred_sup, labels_sup)\n",
        "\n",
        "        # Unsupervised part\n",
        "        trainloader_unsup_iter = iter(trainloader_unsup)\n",
        "        loss_strong_unsup = torch.tensor([0.0], device=device)\n",
        "        for b_batch_idx in range(MU):\n",
        "            images_unsup, _ = trainloader_unsup_iter.__next__()\n",
        "            images_unsup = images_unsup.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                image_unsup_weak = weak_transform(images_unsup)\n",
        "            logits_weak_pred_unsup = model.forward(image_unsup_weak)\n",
        "            proba_weak_pred_unsup = torch.nn.functional.softmax(logits_weak_pred_unsup, dim=1)\n",
        "            label_weak_pred_unsup = proba_weak_pred_unsup.argmax(dim=1)\n",
        "            confidence_mask = proba_weak_pred_unsup.max(dim=1)[0] > TAU\n",
        "\n",
        "            if len(confidence_mask) != 0:\n",
        "                continue\n",
        "\n",
        "            image_unsup_strong = strong_transform(images_unsup)\n",
        "            logits_strong_pred_unsup = model.forward(image_unsup_strong)\n",
        "            proba_strong_pred_unsup = torch.nn.functional.softmax(logits_strong_pred_unsup, dim=1)\n",
        "            label_strong_pred_unsup = proba_strong_pred_unsup.argmax(dim=1)\n",
        "\n",
        "            if len(confidence_mask) != 0:\n",
        "                loss_strong_unsup_ = unsupervised_criterion.forward(logits_strong_pred_unsup[confidence_mask], label_weak_pred_unsup[confidence_mask])#*(len(confidence_mask)/images_unsup.size(0))\n",
        "                loss_strong_unsup  = loss_strong_unsup + loss_strong_unsup_\n",
        "        # logits under the strong against the label under the weak for confident enough predictions\n",
        "\n",
        "        # Total loss\n",
        "        loss = loss_weak_sup + LAMBDA_U*loss_strong_unsup\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        # update metrics\n",
        "        epoch_loss += loss.item()*(images_sup.size(0) + images_unsup.size(0))/(len(trainset_sup) + LAMBDA_U*len(trainset_unsup))\n",
        "        # print statistics\n",
        "        pbar.set_postfix(\n",
        "            {\n",
        "                \"train_loss_sup\": f\"{loss_weak_sup.item():.5f}\",\n",
        "                \"confident\": f\"{confidence_mask.sum().item()}\",\n",
        "                \"train_loss_unsup\": f\"{loss_strong_unsup.item():.5f}\",\n",
        "                \"train_loss_total\": f\"{loss.item():.5f}\",\n",
        "                \"epoch_loss\": f\"{epoch_loss:.5f}\",\n",
        "                \"lr\": f\"{optimizer.param_groups[0]['lr']:.3f}\",\n",
        "            }\n",
        "        )\n",
        "    # scheduler.step()\n",
        "    \n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_epoch_loss = 0.0\n",
        "        for (images_val, label_val) in (pbar := tqdm(validloader, desc=f\"Epoch val {epoch: >1}\")):\n",
        "            images_val, label_val = images_val.to(device), label_val.to(device)\n",
        "            outputs_val = model.forward(images_val)\n",
        "            label_pred_val = outputs_val.argmax(dim=1)\n",
        "            loss_val = supervised_criterion.forward(outputs_val, label_val)\n",
        "            val_epoch_loss += loss_val.item()*images_val.size(0)/len(validloader)\n",
        "            pbar.set_postfix(\n",
        "                {\n",
        "                    \"val_loss\": f\"{loss_val.item():.2f}\",\n",
        "                    \"val_epoch_loss\": f\"{val_epoch_loss:.2f}\",\n",
        "                    \"accuracy\": f\"{accuracy(label_val.cpu(), label_pred_val.cpu()):.2f}\",\n",
        "                }\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "strong_transform(images_unsup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weak_transform(images_unsup).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weak_transform(image_unsup).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_unsup.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weak_transform(image_unsup).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.randn(64, 3, 32, 32)\n",
        "weak_transform(x).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainloader_sup.__len__()*MU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainloader_unsup.__len__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_unsup_weak.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_unsup_weak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_sup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "model = ConvNN()\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=BETA)\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Training\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for (images, labels) in (pbar := tqdm(trainloader, desc=f\"Epoch {epoch: >5}\")) :\n",
        "        # extract mini batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # forward pass\n",
        "        outputs = model.forward(images)\n",
        "        label_pred = outputs.argmax(dim=1)\n",
        "        loss = criterion.forward(outputs, labels)\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        # update metrics\n",
        "        epoch_loss += loss.item()*images.size(0)/len(trainloader)\n",
        "        # print statistics\n",
        "        pbar.set_postfix(\n",
        "            {\n",
        "                \"train_loss\": f\"{loss.item():.2f}\",\n",
        "                \"epoch_loss\": f\"{epoch_loss:.2f}\",\n",
        "                \"lr\": f\"{optimizer.param_groups[0]['lr']:.3f}\",\n",
        "            }\n",
        "        )\n",
        "    # scheduler.step()\n",
        "\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_epoch_loss = 0.0\n",
        "        for (images_val, label_val) in (pbar := tqdm(validloader, desc=f\"Epoch val {epoch: >1}\")):\n",
        "            images_val, label_val = images_val.to(device), label_val.to(device)\n",
        "            outputs_val = model.forward(images_val)\n",
        "            label_pred_val = outputs_val.argmax(dim=1)\n",
        "            loss_val = criterion.forward(outputs_val, label_val)\n",
        "            val_epoch_loss += loss_val.item()*images_val.size(0)/len(validloader)\n",
        "            pbar.set_postfix(\n",
        "                {\n",
        "                    \"val_loss\": f\"{loss_val.item():.2f}\",\n",
        "                    \"val_epoch_loss\": f\"{val_epoch_loss:.2f}\",\n",
        "                    \"accuracy\": f\"{accuracy(label_val.cpu(), label_pred_val.cpu()):.2f}\",\n",
        "                }\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
